<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GazeCursor ¬∑ eye controlled mouse (assistive)</title>
    <!-- TensorFlow and MediaPipe (FaceMesh) via CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.2.0/dist/tf-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.2.0/dist/tf-converter.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.2.0/dist/tf-backend-webgl.min.js"></script>
    <!-- face-landmarks-detection (uses MediaPipe) -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.0/dist/face-landmarks-detection.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Roboto, system-ui, sans-serif;
            user-select: none;
        }
        body {
            min-height: 100vh;
            background: linear-gradient(145deg, #0b1729 0%, #1b2f44 100%);
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 16px;
        }
        .card {
            max-width: 1400px;
            width: 100%;
            background: rgba(255,255,255,0.06);
            backdrop-filter: blur(8px);
            border-radius: 48px;
            padding: 24px;
            box-shadow: 0 25px 50px -12px rgba(0,0,0,0.8), inset 0 1px 2px rgba(255,255,255,0.1);
            border: 1px solid rgba(255,255,255,0.15);
        }
        .main-panel {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }
        .video-section {
            flex: 2;
            min-width: 360px;
            position: relative;
            border-radius: 32px;
            overflow: hidden;
            background: #0a121c;
            border: 2px solid rgba(255,255,255,0.2);
            box-shadow: 0 20px 30px -10px black;
        }
        .video-container {
            position: relative;
            width: 100%;
            aspect-ratio: 4/3;
            background: #11212e;
        }
        #webcam {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1);  /* mirror for intuitive movement */
            display: block;
        }
        #landmark-canvas {
            position: absolute;
            width: 100%;
            height: 100%;
            top: 0;
            left: 0;
            pointer-events: none;
            transform: scaleX(-1); /* match mirrored webcam */
        }
        .toggle-landmarks {
            position: absolute;
            bottom: 16px;
            right: 16px;
            background: rgba(0,20,40,0.7);
            backdrop-filter: blur(4px);
            border: 1px solid cyan;
            color: white;
            padding: 10px 20px;
            border-radius: 60px;
            font-weight: 600;
            letter-spacing: 0.5px;
            cursor: pointer;
            border: 1px solid #4cc9f0;
            box-shadow: 0 0 15px #4cc9f066;
            transition: 0.2s;
            z-index: 10;
        }
        .toggle-landmarks:hover {
            background: #1e4b6e;
        }
        .cursor-status {
            position: absolute;
            top: 16px;
            left: 16px;
            background: #0f212f;
            padding: 10px 20px;
            border-radius: 60px;
            border-left: 6px solid #0ef;
            color: white;
            font-weight: 600;
            box-shadow: 0 10px 20px -10px black;
            z-index: 10;
            backdrop-filter: blur(4px);
        }
        .cursor-status span {
            color: #0ef;
            margin-left: 6px;
        }
        .info-section {
            flex: 1;
            min-width: 280px;
            background: rgba(10, 25, 40, 0.7);
            backdrop-filter: blur(8px);
            border-radius: 32px;
            padding: 24px 20px;
            border: 1px solid #3a5f7a;
            color: #e3f2fd;
            display: flex;
            flex-direction: column;
            gap: 24px;
        }
        .calibration-box {
            background: #0e2a38;
            border-radius: 24px;
            padding: 20px;
            border: 1px solid #2c5f8a;
        }
        .calibration-box h3 {
            font-weight: 400;
            margin-bottom: 18px;
            display: flex;
            gap: 8px;
            align-items: center;
            color: #b2e6ff;
        }
        .calibration-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 12px;
            margin-bottom: 16px;
        }
        .calib-btn {
            background: #1a4055;
            border: none;
            color: white;
            padding: 14px 0;
            border-radius: 30px;
            font-weight: 600;
            font-size: 1.1rem;
            box-shadow: 0 6px 0 #0b1f2b;
            transition: 0.08s linear;
            cursor: pointer;
            border: 1px solid #3985b3;
        }
        .calib-btn:active {
            transform: translateY(5px);
            box-shadow: 0 1px 0 #0b1f2b;
        }
        .calib-btn.active {
            background: #3f9ed6;
            box-shadow: 0 0 20px #00ccff;
            border-color: white;
        }
        .offset-row {
            display: flex;
            justify-content: space-between;
            background: #0f1e2b;
            padding: 12px 18px;
            border-radius: 40px;
            font-size: 0.9rem;
            border: 1px solid #20668b;
        }
        .badge {
            background: #0e2f40;
            padding: 6px 16px;
            border-radius: 40px;
            color: #9fdbfc;
        }
        .virtual-cursor {
            position: fixed;
            width: 32px;
            height: 32px;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 50%;
            box-shadow: 0 0 30px cyan, 0 8px 20px rgba(0,0,0,0.5);
            border: 3px solid #00ccff;
            transform: translate(-50%, -50%);
            pointer-events: none;
            z-index: 9999;
            transition: width 0.1s, height 0.1s, background 0.1s;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 18px;
            color: #0a1a2a;
            font-weight: bold;
            backdrop-filter: blur(2px);
        }
        .virtual-cursor.click-anim {
            width: 48px;
            height: 48px;
            background: #f0f9ff;
            border-color: #ffaa00;
            box-shadow: 0 0 50px orange;
        }
        .virtual-cursor.disabled {
            opacity: 0.3;
            background: #555;
            border-color: gray;
            box-shadow: none;
        }
        .instructions {
            background: #0b1f2c;
            border-radius: 20px;
            padding: 18px;
            font-size: 0.95rem;
            border-left: 6px solid #4cc9f0;
        }
        .instructions p {
            margin: 8px 0;
            display: flex;
            align-items: center;
            gap: 12px;
        }
        .security-note {
            background: #132a35;
            border-radius: 30px;
            padding: 12px 18px;
            text-align: center;
            border: 1px solid #2aa9c9;
            font-weight: 500;
        }
        .footer-buttons {
            display: flex;
            gap: 14px;
            flex-wrap: wrap;
            margin-top: 10px;
        }
        .lg-btn {
            background: #244b63;
            border: none;
            color: white;
            padding: 16px 20px;
            border-radius: 60px;
            font-size: 1.2rem;
            flex: 1 1 auto;
            font-weight: 600;
            box-shadow: 0 6px 0 #0b202b;
            transition: 0.08s;
            cursor: pointer;
            border: 1px solid #5aa9d4;
        }
        .lg-btn:active {
            transform: translateY(5px);
            box-shadow: 0 1px 0 #0b202b;
        }
    </style>
</head>
<body>
<div class="card">
    <div class="main-panel">
        <!-- VIDEO + OVERLAY -->
        <div class="video-section">
            <div class="video-container">
                <video id="webcam" autoplay playsinline></video>
                <canvas id="landmark-canvas"></canvas>
                <div class="cursor-status">
                    üñ±Ô∏è cursor <span id="cursorState">enabled</span>
                </div>
                <button class="toggle-landmarks" id="toggleLandmarksBtn">üëÅÔ∏è hide landmarks</button>
            </div>
        </div>

        <!-- SIDE PANEL (calibration + UI) -->
        <div class="info-section">
            <div style="display: flex; gap: 10px; align-items: center;">
                <span style="font-size: 32px;">ü™û</span>
                <span style="font-weight: 300;">eye‚Äëtracking assist</span>
            </div>
            <!-- calibration card -->
            <div class="calibration-box">
                <h3>üìê 1‚Äëtap calibration (camera above you)</h3>
                <div class="calibration-grid">
                    <button class="calib-btn" id="calibCenter">‚¨§ center</button>
                    <button class="calib-btn" id="calibLeft">‚Üê left</button>
                    <button class="calib-btn" id="calibRight">‚Üí right</button>
                    <button class="calib-btn" id="calibUp">‚Üë up</button>
                    <button class="calib-btn" id="calibDown">‚Üì down</button>
                    <button class="calib-btn" id="resetCalib">‚ü≤ reset</button>
                </div>
                <div class="offset-row">
                    <span>üîµ offsets</span>
                    <span class="badge" id="offsetDisplay">x:0 y:0</span>
                </div>
                <div style="margin-top: 12px; font-size: 0.85rem; opacity: 0.8;">press button while looking in that direction (steady gaze)</div>
            </div>

            <!-- cursor enable/disable + blink info -->
            <div class="footer-buttons">
                <button class="lg-btn" id="toggleCursorBtn">üñ±Ô∏è toggle cursor</button>
                <button class="lg-btn" id="resetOffsetsBtn">üéØ reset offsets</button>
            </div>

            <!-- blink feedback -->
            <div style="display: flex; gap: 20px; justify-content: space-around; background: #0f2838; border-radius: 60px; padding: 14px;">
                <span>üòâ blink ‚Üí click</span>
                <span>üòúüòú double blink ‚Üí toggle</span>
            </div>

            <!-- instructions & privacy -->
            <div class="instructions">
                <p>üí° <strong>lighting & posture</strong></p>
                <p>‚òÄÔ∏è face well lit, no strong backlight</p>
                <p>ü™ë sit centered, camera slightly above eyes</p>
                <p>üëÅÔ∏è keep a neutral expression</p>
            </div>
            <div class="security-note">
                üîí camera data never leaves your device ‚Äî 100% frontend
            </div>
        </div>
    </div>
</div>

<!-- VIRTUAL CURSOR (div) -->
<div id="virtualCursor" class="virtual-cursor">‚ö°</div>

<script>
(function() {
    // ---------- DOM elements ----------
    const video = document.getElementById('webcam');
    const canvas = document.getElementById('landmark-canvas');
    const ctx = canvas.getContext('2d');
    const cursorDiv = document.getElementById('virtualCursor');
    const cursorStateSpan = document.getElementById('cursorState');
    const toggleCursorBtn = document.getElementById('toggleCursorBtn');
    const toggleLandmarksBtn = document.getElementById('toggleLandmarksBtn');
    const calibCenter = document.getElementById('calibCenter');
    const calibLeft = document.getElementById('calibLeft');
    const calibRight = document.getElementById('calibRight');
    const calibUp = document.getElementById('calibUp');
    const calibDown = document.getElementById('calibDown');
    const resetCalib = document.getElementById('resetCalib');
    const resetOffsetsBtn = document.getElementById('resetOffsetsBtn');
    const offsetDisplay = document.getElementById('offsetDisplay');

    // ---------- global state ----------
    let faceDetector = null;
    let lastVideoTime = -1;
    let landmarks = null;

    // cursor enable
    let cursorEnabled = true;

    // landmark overlay flag
    let drawLandmarks = true;  // default on

    // gaze smoothing (moving average)
    const SMOOTH_FRAMES = 6;
    const gazeHistory = { x: [], y: [] };
    let smoothGazeX = 0.5;  // normalized 0..1
    let smoothGazeY = 0.5;

    // calibration offsets (neutral gaze mapped to 0.5, 0.5)
    // offsets are applied as shift: gaze = rawGaze + offset (clamped)
    let offsetX = 0.0;   // range ~ -0.3 .. 0.3
    let offsetY = 0.0;   // we will add vertical compensation (camera above)

    // FIXED VERTICAL BIAS: camera is above user => eyes look slightly upward to camera.
    // we want neutral (straight ahead) to map to 0.5. So we ADD a positive offset (downward shift).
    const VERTICAL_CAMERA_ABOVE_COMPENSATION = 0.12;  // tuned for typical laptop

    // blink detection
    const EAR_THRESHOLD = 0.22;      // eye aspect ratio threshold
    const BLINK_FRAMES = 3;           // consecutive frames to confirm blink
    let leftEyeRatio = 1.0;
    let rightEyeRatio = 1.0;
    let blinkCounter = 0;
    let blinkCooldown = 0;            // frames after click to avoid double
    let doubleBlinkWindow = [];        // timestamps of recent blinks (ms)
    const DOUBLE_BLINK_MS = 400;       // max interval for double blink

    // indices from MediaPipe facemesh (iris + eye contour)
    // left eye contour: 33,133,157,158,159,160,161,173  (simplified: we use 33,133 for aspect)
    // right eye contour: 362,263,387,386,385,384,398,466
    // we'll use landmarks 33 (left eye left corner) , 133 (right corner) , 159 (top) , 145 (bottom) for left EAR
    // for right: 362,263,386,374? we use consistent: 362 (right corner), 263 (left corner), 386 (top), 374 (bottom)
    const LEFT_EYE_INDICES = [33, 133, 159, 145];   // left, right, top, bottom
    const RIGHT_EYE_INDICES = [362, 263, 386, 374]; // left, right, top, bottom (for right eye mirrored)

    // for gaze we use iris (left iris center: 468, right iris: 473) and also average
    const IRIS_LEFT = 468;
    const IRIS_RIGHT = 473;
    // additional head pose? we'll use normalized iris positions

    // ---------- helper: eye aspect ratio ----------
    function eyeAspectRatio(landmarks, eyeIdx) {
        try {
            // eyeIdx should be array of 4: [leftCorner, rightCorner, top, bottom]
            const left = landmarks[eyeIdx[0]];
            const right = landmarks[eyeIdx[1]];
            const top = landmarks[eyeIdx[2]];
            const bottom = landmarks[eyeIdx[3]];
            if (!left || !right || !top || !bottom) return 1.0;
            // width = distance between corners
            const width = Math.hypot(right.x - left.x, right.y - left.y);
            // height = distance between top and bottom
            const height = Math.hypot(bottom.x - top.x, bottom.y - top.y);
            if (width === 0) return 1.0;
            return height / width;
        } catch (e) {
            return 1.0;
        }
    }

    // ---------- init camera & face detector ----------
    async function init() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            await video.play();
            // set canvas dimensions
            video.addEventListener('loadeddata', () => {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            });

            // load face detector (MediaPipe)
            const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
            const detectorConfig = {
                runtime: 'mediapipe',
                solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh',
                maxFaces: 1,
                refineLandmarks: true,   // get iris
            };
            faceDetector = await faceLandmarksDetection.createDetector(model, detectorConfig);
            requestAnimationFrame(detectAndTrack);
        } catch (err) {
            alert('Camera access needed for eye tracking.');
            console.error(err);
        }
    }

    // ---------- map gaze to cursor position with offsets + compensation ----------
    function updateCursorFromGaze() {
        if (!cursorEnabled) {
            cursorDiv.classList.add('disabled');
            return;
        } else {
            cursorDiv.classList.remove('disabled');
        }

        if (!landmarks) return;

        try {
            // get iris centers (normalized 0..1) - use both eyes for robustness
            const leftIris = landmarks[IRIS_LEFT];
            const rightIris = landmarks[IRIS_RIGHT];
            if (!leftIris || !rightIris) return;

            // average x and y (already normalized 0-1)
            let rawX = (leftIris.x + rightIris.x) / 2;
            let rawY = (leftIris.y + rightIris.y) / 2;

            // apply vertical compensation: camera above => add positive offset (down)
            // and horizontal offset from calibration
            let compensatedX = rawX + offsetX;
            let compensatedY = rawY + offsetY + VERTICAL_CAMERA_ABOVE_COMPENSATION;

            // clamp to 0..1
            compensatedX = Math.min(1, Math.max(0, compensatedX));
            compensatedY = Math.min(1, Math.max(0, compensatedY));

            // smoothing (moving average)
            gazeHistory.x.push(compensatedX);
            gazeHistory.y.push(compensatedY);
            if (gazeHistory.x.length > SMOOTH_FRAMES) gazeHistory.x.shift();
            if (gazeHistory.y.length > SMOOTH_FRAMES) gazeHistory.y.shift();

            const avgX = gazeHistory.x.reduce((a, b) => a + b, 0) / gazeHistory.x.length;
            const avgY = gazeHistory.y.reduce((a, b) => a + b, 0) / gazeHistory.y.length;

            smoothGazeX = avgX;
            smoothGazeY = avgY;

            // map to viewport
            const cursorX = smoothGazeX * window.innerWidth;
            const cursorY = smoothGazeY * window.innerHeight;

            cursorDiv.style.left = cursorX + 'px';
            cursorDiv.style.top = cursorY + 'px';
        } catch (e) { /* ignore */ }
    }

    // ---------- blink processing ----------
    function processBlink() {
        if (!landmarks) return false;
        const leftEAR = eyeAspectRatio(landmarks, LEFT_EYE_INDICES);
        const rightEAR = eyeAspectRatio(landmarks, RIGHT_EYE_INDICES);
        leftEyeRatio = leftEAR;
        rightEyeRatio = rightEAR;
        const ear = (leftEAR + rightEAR) / 2;

        const blinked = ear < EAR_THRESHOLD;

        // cooldown (prevents rapid fire)
        if (blinkCooldown > 0) {
            blinkCooldown--;
            return false;
        }

        if (blinked) {
            blinkCounter++;
            if (blinkCounter >= BLINK_FRAMES) {
                // blink confirmed
                blinkCounter = 0;
                blinkCooldown = 10;  // frames

                const now = performance.now();
                doubleBlinkWindow.push(now);
                // keep only last 600ms
                doubleBlinkWindow = doubleBlinkWindow.filter(t => now - t < DOUBLE_BLINK_MS);

                if (doubleBlinkWindow.length >= 2) {
                    // double blink: toggle cursor
                    cursorEnabled = !cursorEnabled;
                    cursorStateSpan.innerText = cursorEnabled ? 'enabled' : 'disabled';
                    doubleBlinkWindow = []; // reset
                    // visual feedback
                    cursorDiv.classList.add('click-anim');
                    setTimeout(() => cursorDiv.classList.remove('click-anim'), 200);
                } else {
                    // single blink => click animation
                    cursorDiv.classList.add('click-anim');
                    setTimeout(() => cursorDiv.classList.remove('click-anim'), 200);
                }
                return true;
            }
        } else {
            blinkCounter = 0;
        }
        return false;
    }

    // ---------- draw landmarks on canvas ----------
    function drawFaceMesh(landmarks) {
        if (!drawLandmarks || !landmarks) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            return;
        }
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.fillStyle = '#00ffff';
        ctx.strokeStyle = '#ff66cc';
        ctx.lineWidth = 2;

        // draw iris points (468 left, 473 right) and some contour
        [IRIS_LEFT, IRIS_RIGHT].forEach(idx => {
            const pt = landmarks[idx];
            if (pt) {
                ctx.beginPath();
                ctx.arc(pt.x * canvas.width, pt.y * canvas.height, 4, 0, 2 * Math.PI);
                ctx.fillStyle = '#ffea00';
                ctx.fill();
                ctx.shadowBlur = 15; ctx.shadowColor = 'cyan';
            }
        });

        // draw eye contours (simplified)
        const eyeDrawIndices = [33,133,159,145, 362,263,386,374];
        eyeDrawIndices.forEach(idx => {
            const pt = landmarks[idx];
            if (pt) {
                ctx.beginPath();
                ctx.arc(pt.x * canvas.width, pt.y * canvas.height, 3, 0, 2*Math.PI);
                ctx.fillStyle = '#ff99cc';
                ctx.fill();
            }
        });
        ctx.shadowBlur = 0;
    }

    // ---------- core detection loop ----------
    async function detectAndTrack() {
        if (faceDetector && video.readyState === 4) {
            try {
                const estimationConfig = { flipHorizontal: false }; // we already mirror via canvas/video style
                const faces = await faceDetector.estimateFaces(video, estimationConfig);

                if (faces.length > 0) {
                    landmarks = faces[0].keypoints.map(kp => ({ x: kp.x / video.videoWidth, y: kp.y / video.videoHeight }));
                    // update cursor and blink
                    updateCursorFromGaze();
                    processBlink();
                    drawFaceMesh(landmarks);
                } else {
                    landmarks = null;
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                }
            } catch (e) {
                console.warn(e);
            }
        }
        requestAnimationFrame(detectAndTrack);
    }

    // ---------- calibration setters (offsets) ----------
    function setCalibrationOffset(targetX, targetY) {
        if (!landmarks) {
            alert('No face detected ‚Äì cannot calibrate.');
            return;
        }
        try {
            const leftIris = landmarks[IRIS_LEFT];
            const rightIris = landmarks[IRIS_RIGHT];
            if (!leftIris || !rightIris) return;
            let rawX = (leftIris.x + rightIris.x) / 2;
            let rawY = (leftIris.y + rightIris.y) / 2;

            // desired gaze position (0..1): for center we want 0.5,0.5; left: x~0.2, right: x~0.8, up: y~0.2, down: y~0.8 (but with compensation)
            // we compute offset = desired - raw (compensation is separate)
            let desiredX = 0.5, desiredY = 0.5;
            if (targetX !== undefined) desiredX = targetX;
            if (targetY !== undefined) desiredY = targetY;

            // new offset = desired - raw  (but we want offsets to be added later: gaze = raw + offset + compensation)
            // So offset = desired - raw.
            let newOffsetX = desiredX - rawX;
            let newOffsetY = desiredY - rawY;

            offsetX = newOffsetX;
            offsetY = newOffsetY;

            updateOffsetDisplay();
        } catch (e) {}
    }

    function resetOffsets() {
        offsetX = 0.0;
        offsetY = 0.0;
        updateOffsetDisplay();
    }

    function updateOffsetDisplay() {
        offsetDisplay.innerText = `x:${offsetX.toFixed(3)} y:${offsetY.toFixed(3)}`;
    }

    // ---------- UI event listeners ----------
    toggleCursorBtn.addEventListener('click', () => {
        cursorEnabled = !cursorEnabled;
        cursorStateSpan.innerText = cursorEnabled ? 'enabled' : 'disabled';
    });

    toggleLandmarksBtn.addEventListener('click', () => {
        drawLandmarks = !drawLandmarks;
        toggleLandmarksBtn.innerText = drawLandmarks ? 'üëÅÔ∏è hide landmarks' : 'üëÅÔ∏è show landmarks';
        if (!drawLandmarks) ctx.clearRect(0, 0, canvas.width, canvas.height);
    });

    calibCenter.addEventListener('click', () => setCalibrationOffset(0.5, 0.5));
    calibLeft.addEventListener('click', () => setCalibrationOffset(0.2, 0.5));
    calibRight.addEventListener('click', () => setCalibrationOffset(0.8, 0.5));
    calibUp.addEventListener('click', () => setCalibrationOffset(0.5, 0.2));
    calibDown.addEventListener('click', () => setCalibrationOffset(0.5, 0.8));
    resetCalib.addEventListener('click', resetOffsets);
    resetOffsetsBtn.addEventListener('click', resetOffsets);

    // highlight active button? (optional)
    // start
    init();
    // initial offset display
    updateOffsetDisplay();
})();
</script>
</body>
</html>
